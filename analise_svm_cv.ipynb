{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise Comparativa de Métodos de Validação Cruzada no Desempenho do Classificador SVM para Predição de Doenças Cardíacas\n",
    "\n",
    "Este notebook apresenta uma análise comparativa de diferentes métodos de validação cruzada aplicados a um classificador SVM (Support Vector Machine) para predição de doenças.\n",
    "\n",
    "## Objetivos\n",
    "\n",
    "1. Implementar e comparar diferentes métodos de validação cruzada:\n",
    "   - K-Fold Cross-Validation\n",
    "   - Stratified K-Fold Cross-Validation\n",
    "   - Leave-One-Out Cross-Validation (opcional)\n",
    "\n",
    "2. Avaliar o desempenho do classificador SVM usando múltiplas métricas:\n",
    "   - Acurácia\n",
    "   - Precisão\n",
    "   - Recall\n",
    "   - F1-Score\n",
    "\n",
    "3. Visualizar e comparar os resultados obtidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importação de Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import (\n",
    "    cross_val_score, \n",
    "    KFold, \n",
    "    StratifiedKFold, \n",
    "    LeaveOneOut,\n",
    "    cross_validate\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    f1_score,\n",
    "    make_scorer,\n",
    "    confusion_matrix,\n",
    "    classification_report\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuração de visualização\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Bibliotecas importadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carregamento e Exploração dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega o dataset\n",
    "# Utilizamos o dataset de câncer de mama como proxy para análise de doenças\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Informações básicas\n",
    "print(f\"Dimensões do dataset: {X.shape}\")\n",
    "print(f\"Número de amostras: {X.shape[0]}\")\n",
    "print(f\"Número de características: {X.shape[1]}\")\n",
    "print(f\"\\nDistribuição de classes:\")\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "for label, count in zip(unique, counts):\n",
    "    print(f\"  Classe {label}: {count} amostras ({count/len(y)*100:.2f}%)\")\n",
    "\n",
    "# Normalização dos dados\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(\"\\nDados normalizados com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Implementação dos Métodos de Validação Cruzada\n",
    "\n",
    "### 3.1 K-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_kfold(X, y, n_splits=10, random_state=42):\n",
    "    \"\"\"\n",
    "    Realiza K-Fold Cross-Validation.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"K-Fold Cross-Validation (k={n_splits})\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    clf = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=random_state)\n",
    "    cv = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    scoring = {\n",
    "        'accuracy': 'accuracy',\n",
    "        'precision': make_scorer(precision_score, zero_division=0),\n",
    "        'recall': make_scorer(recall_score, zero_division=0),\n",
    "        'f1': make_scorer(f1_score, zero_division=0)\n",
    "    }\n",
    "    \n",
    "    scores = cross_validate(clf, X, y, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "    \n",
    "    results = {\n",
    "        'method': f'K-Fold (k={n_splits})',\n",
    "        'accuracy': scores['test_accuracy'],\n",
    "        'precision': scores['test_precision'],\n",
    "        'recall': scores['test_recall'],\n",
    "        'f1': scores['test_f1']\n",
    "    }\n",
    "    \n",
    "    # Imprime resultados\n",
    "    for metric in ['accuracy', 'precision', 'recall', 'f1']:\n",
    "        mean = results[metric].mean()\n",
    "        std = results[metric].std()\n",
    "        print(f\"{metric.capitalize():12s}: {mean:.4f} (+/- {std:.4f})\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Executa K-Fold com diferentes valores de k\n",
    "kfold_5 = evaluate_kfold(X_scaled, y, n_splits=5)\n",
    "kfold_10 = evaluate_kfold(X_scaled, y, n_splits=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Stratified K-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_stratified_kfold(X, y, n_splits=10, random_state=42):\n",
    "    \"\"\"\n",
    "    Realiza Stratified K-Fold Cross-Validation.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Stratified K-Fold Cross-Validation (k={n_splits})\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    clf = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=random_state)\n",
    "    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    scoring = {\n",
    "        'accuracy': 'accuracy',\n",
    "        'precision': make_scorer(precision_score, zero_division=0),\n",
    "        'recall': make_scorer(recall_score, zero_division=0),\n",
    "        'f1': make_scorer(f1_score, zero_division=0)\n",
    "    }\n",
    "    \n",
    "    scores = cross_validate(clf, X, y, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "    \n",
    "    results = {\n",
    "        'method': f'Stratified K-Fold (k={n_splits})',\n",
    "        'accuracy': scores['test_accuracy'],\n",
    "        'precision': scores['test_precision'],\n",
    "        'recall': scores['test_recall'],\n",
    "        'f1': scores['test_f1']\n",
    "    }\n",
    "    \n",
    "    # Imprime resultados\n",
    "    for metric in ['accuracy', 'precision', 'recall', 'f1']:\n",
    "        mean = results[metric].mean()\n",
    "        std = results[metric].std()\n",
    "        print(f\"{metric.capitalize():12s}: {mean:.4f} (+/- {std:.4f})\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Executa Stratified K-Fold com diferentes valores de k\n",
    "stratified_5 = evaluate_stratified_kfold(X_scaled, y, n_splits=5)\n",
    "stratified_10 = evaluate_stratified_kfold(X_scaled, y, n_splits=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Comparação Visual dos Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepara dados para visualização\n",
    "all_results = {\n",
    "    'K-Fold (k=5)': kfold_5,\n",
    "    'K-Fold (k=10)': kfold_10,\n",
    "    'Stratified K-Fold (k=5)': stratified_5,\n",
    "    'Stratified K-Fold (k=10)': stratified_10\n",
    "}\n",
    "\n",
    "# Cria figura com múltiplos subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Análise Comparativa de Métodos de Validação Cruzada\\nClassificador SVM', \n",
    "             fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Comparação de Acurácia\n",
    "ax1 = axes[0, 0]\n",
    "methods = list(all_results.keys())\n",
    "accuracies = [results['accuracy'].mean() for results in all_results.values()]\n",
    "errors = [results['accuracy'].std() for results in all_results.values()]\n",
    "\n",
    "bars = ax1.bar(range(len(methods)), accuracies, yerr=errors, \n",
    "               capsize=5, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "ax1.set_xlabel('Método', fontweight='bold')\n",
    "ax1.set_ylabel('Acurácia', fontweight='bold')\n",
    "ax1.set_title('Comparação de Acurácia', fontweight='bold')\n",
    "ax1.set_xticks(range(len(methods)))\n",
    "ax1.set_xticklabels(methods, rotation=45, ha='right')\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for bar, val in zip(bars, accuracies):\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,\n",
    "            f'{val:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# 2. Comparação de Múltiplas Métricas\n",
    "ax2 = axes[0, 1]\n",
    "x = np.arange(len(methods))\n",
    "width = 0.2\n",
    "\n",
    "metrics_data = {\n",
    "    'Accuracy': [results['accuracy'].mean() for results in all_results.values()],\n",
    "    'Precision': [results['precision'].mean() for results in all_results.values()],\n",
    "    'Recall': [results['recall'].mean() for results in all_results.values()],\n",
    "    'F1-Score': [results['f1'].mean() for results in all_results.values()]\n",
    "}\n",
    "\n",
    "colors = ['skyblue', 'lightgreen', 'lightcoral', 'plum']\n",
    "for i, (metric, values) in enumerate(metrics_data.items()):\n",
    "    offset = (i - 1.5) * width\n",
    "    ax2.bar(x + offset, values, width, label=metric, \n",
    "           color=colors[i], edgecolor='black', alpha=0.7)\n",
    "\n",
    "ax2.set_xlabel('Método', fontweight='bold')\n",
    "ax2.set_ylabel('Score', fontweight='bold')\n",
    "ax2.set_title('Comparação de Múltiplas Métricas', fontweight='bold')\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(methods, rotation=45, ha='right')\n",
    "ax2.legend()\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 3. Box Plot - Distribuição de Acurácia\n",
    "ax3 = axes[1, 0]\n",
    "accuracy_data = [results['accuracy'] for results in all_results.values()]\n",
    "bp = ax3.boxplot(accuracy_data, labels=methods, patch_artist=True)\n",
    "\n",
    "for patch in bp['boxes']:\n",
    "    patch.set_facecolor('lightblue')\n",
    "    patch.set_alpha(0.7)\n",
    "\n",
    "ax3.set_xlabel('Método', fontweight='bold')\n",
    "ax3.set_ylabel('Acurácia', fontweight='bold')\n",
    "ax3.set_title('Distribuição de Acurácia', fontweight='bold')\n",
    "ax3.set_xticklabels(methods, rotation=45, ha='right')\n",
    "ax3.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 4. Heatmap - Comparação de Métricas\n",
    "ax4 = axes[1, 1]\n",
    "metrics_matrix = np.array([\n",
    "    [results['accuracy'].mean(), results['precision'].mean(), \n",
    "     results['recall'].mean(), results['f1'].mean()]\n",
    "    for results in all_results.values()\n",
    "])\n",
    "\n",
    "im = ax4.imshow(metrics_matrix.T, cmap='YlGnBu', aspect='auto')\n",
    "ax4.set_xticks(range(len(methods)))\n",
    "ax4.set_yticks(range(4))\n",
    "ax4.set_xticklabels(methods, rotation=45, ha='right')\n",
    "ax4.set_yticklabels(['Accuracy', 'Precision', 'Recall', 'F1-Score'])\n",
    "ax4.set_title('Heatmap de Métricas', fontweight='bold')\n",
    "\n",
    "# Adiciona valores no heatmap\n",
    "for i in range(4):\n",
    "    for j in range(len(methods)):\n",
    "        text = ax4.text(j, i, f'{metrics_matrix[j, i]:.3f}',\n",
    "                       ha=\"center\", va=\"center\", color=\"black\", fontsize=9)\n",
    "\n",
    "plt.colorbar(im, ax=ax4)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Análise Estatística Detalhada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria DataFrame com resultados\n",
    "results_df = pd.DataFrame({\n",
    "    'Método': methods,\n",
    "    'Acurácia (média)': [results['accuracy'].mean() for results in all_results.values()],\n",
    "    'Acurácia (std)': [results['accuracy'].std() for results in all_results.values()],\n",
    "    'Precisão (média)': [results['precision'].mean() for results in all_results.values()],\n",
    "    'Precisão (std)': [results['precision'].std() for results in all_results.values()],\n",
    "    'Recall (média)': [results['recall'].mean() for results in all_results.values()],\n",
    "    'Recall (std)': [results['recall'].std() for results in all_results.values()],\n",
    "    'F1-Score (média)': [results['f1'].mean() for results in all_results.values()],\n",
    "    'F1-Score (std)': [results['f1'].std() for results in all_results.values()]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"RESUMO ESTATÍSTICO DOS RESULTADOS\")\n",
    "print(\"=\"*100)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Identifica o melhor método\n",
    "best_idx = results_df['Acurácia (média)'].idxmax()\n",
    "print(f\"\\n{'='*100}\")\n",
    "print(f\"Melhor Método (Acurácia): {results_df.loc[best_idx, 'Método']}\")\n",
    "print(f\"Acurácia: {results_df.loc[best_idx, 'Acurácia (média)']:.4f} (+/- {results_df.loc[best_idx, 'Acurácia (std)']:.4f})\")\n",
    "print(f\"{'='*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusões\n",
    "\n",
    "### Principais Observações:\n",
    "\n",
    "1. **K-Fold vs Stratified K-Fold**: \n",
    "   - O Stratified K-Fold mantém a proporção de classes em cada fold\n",
    "   - Especialmente importante para datasets desbalanceados\n",
    "   - Geralmente oferece estimativas mais confiáveis\n",
    "\n",
    "2. **Impacto do número de folds**:\n",
    "   - Mais folds (k=10) geralmente resultam em estimativas mais estáveis\n",
    "   - Menos folds (k=5) são computacionalmente mais eficientes\n",
    "   - Trade-off entre viés e variância\n",
    "\n",
    "3. **Variabilidade dos resultados**:\n",
    "   - O desvio padrão indica a estabilidade do método\n",
    "   - Métodos com menor desvio padrão são mais consistentes\n",
    "\n",
    "4. **Escolha do método**:\n",
    "   - Para datasets balanceados: K-Fold é suficiente\n",
    "   - Para datasets desbalanceados: Prefira Stratified K-Fold\n",
    "   - Para datasets pequenos: Considere Leave-One-Out (não implementado aqui por custo computacional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Usando a Classe de Análise\n",
    "\n",
    "Alternativamente, você pode usar a classe `SVMCrossValidationAnalysis` do módulo `svm_cv_analysis.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from svm_cv_analysis import SVMCrossValidationAnalysis\n",
    "\n",
    "# # Inicializa análise\n",
    "# analysis = SVMCrossValidationAnalysis(random_state=42)\n",
    "\n",
    "# # Carrega dados\n",
    "# analysis.load_data()\n",
    "\n",
    "# # Executa todos os métodos\n",
    "# analysis.run_all_methods(k_values=[5, 10], include_loo=False)\n",
    "\n",
    "# # Gera visualizações\n",
    "# analysis.create_comparison_plots('cv_comparison.png')\n",
    "\n",
    "# # Gera relatório\n",
    "# analysis.generate_report()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
