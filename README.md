# summit2025

# An√°lise Comparativa de M√©todos de Valida√ß√£o Cruzada no Desempenho do Classificador SVM
### *Comparative Analysis of Cross-Validation Methods on the Performance of an SVM Classifier for Heart Disease Prediction*

---

## Vis√£o Geral do Projeto

Este projeto realiza uma an√°lise comparativa de duas estrat√©gias de valida√ß√£o cruzada (CV), **K-Fold** e **StratifiedShuffleSplit**, para avaliar o desempenho de um classificador de M√°quina de Vetores de Suporte (SVM) na predi√ß√£o de doen√ßas card√≠acas.

A aplica√ß√£o de modelos de aprendizado de m√°quina na √°rea biom√©dica exige avalia√ß√µes rigorosas para garantir a confiabilidade dos resultados . A valida√ß√£o cruzada √© uma t√©cnica fundamental para estimar a capacidade de generaliza√ß√£o de um classificador, prevenindo o superajuste (overfitting) . Este estudo explora como a escolha do m√©todo de CV pode influenciar a performance estimada do modelo, um fator crucial para sua interpreta√ß√£o e aplica√ß√£o pr√°tica .

## üéØ Objetivo

O objetivo principal √© comparar o desempenho de um classificador SVM na predi√ß√£o de doen√ßas card√≠acas, avaliando o impacto de duas estrat√©gias de valida√ß√£o cruzada :
1.  **K-Fold com 10 parti√ß√µes (KFold-10)**
2.  **StratifiedShuffleSplit com 10 divis√µes e 25% dos dados para teste**

## üìä Dataset

Foi utilizado o dataset **Heart Disease (Cleveland)**, contendo dados cl√≠nicos de 303 pacientes. O conjunto de dados √© composto por 13 atributos cl√≠nicos (features) e uma vari√°vel alvo que indica a presen√ßa ou aus√™ncia de doen√ßa card√≠aca .

## üõ†Ô∏è Metodologia

A an√°lise foi conduzida em um notebook Jupyter (`HD_Cleveland.ipynb`) seguindo os seguintes passos:

1.  **Pr√©-processamento:** Os atributos num√©ricos foram padronizados com a t√©cnica `StandardScaler`. Para evitar vazamento de dados (data leakage), este processo foi integrado a um `Pipeline` do Scikit-learn, garantindo que a padroniza√ß√£o fosse aplicada apenas nos dados de treino de cada itera√ß√£o da valida√ß√£o cruzada .

2.  **Modelo e Otimiza√ß√£o:** O modelo de classifica√ß√£o utilizado foi o **M√°quina de Vetores de Suporte (SVC)**. Seus hiperpar√¢metros (`C`, `kernel` e `gamma`) foram otimizados atrav√©s do `GridSearchCV` para encontrar a melhor combina√ß√£o para cada estrat√©gia de CV .

3.  **Valida√ß√£o Cruzada:** As duas estrat√©gias (KFold-10 e StratifiedShuffleSplit) foram aplicadas para treinar e validar o modelo . O desempenho foi medido pela acur√°cia m√©dia obtida em cada abordagem .

4.  **Avalia√ß√£o de Desempenho:** Al√©m da acur√°cia, foram geradas matrizes de confus√£o e relat√≥rios de classifica√ß√£o para analisar a distribui√ß√£o dos erros e a performance do modelo em m√©tricas como precis√£o, recall e F1-score .

## üìà Resultados

A an√°lise revelou os seguintes resultados principais:

* **Acur√°cia M√©dia:** Ambas as estrat√©gias de valida√ß√£o cruzada apresentaram resultados de acur√°cia m√©dia muito pr√≥ximos .
    * **KFold-10:** Acur√°cia de **84,16%** .
    * **StratifiedShuffleSplit:** Acur√°cia de **84,47%** (ligeiramente superior) .

* **Hiperpar√¢metros √ìtimos:** Notou-se que os hiperpar√¢metros ideais encontrados pelo `GridSearchCV` variaram sutilmente entre as duas abordagens, o que destaca como a estrat√©gia de amostragem pode influenciar a otimiza√ß√£o do modelo .

* **An√°lise de Erros:** A matriz de confus√£o demonstrou a capacidade do classificador em distinguir entre pacientes saud√°veis e doentes, embora com uma pequena quantidade de falsos positivos e falsos negativos .

* **Visualiza√ß√µes:** O notebook cont√©m diversas visualiza√ß√µes para uma an√°lise aprofundada:
    * **Gr√°ficos Comparativos:** Comparam a performance dos modelos com kernel linear e RBF para cada estrat√©gia de CV.
    * **Visualiza√ß√£o das Divis√µes:** Ilustra graficamente como KFold e StratifiedShuffleSplit particionam os dados.
    * **Heatmap de Sensibilidade:** Analisa a intera√ß√£o entre os hiperpar√¢metros `C` e `gamma` para o kernel RBF.
    * **Visualiza√ß√£o com PCA:** Reduz a dimensionalidade dos dados para visualizar a fronteira de decis√£o do modelo em um gr√°fico 2D.

## üèÅ Conclus√£o

Os resultados indicam que, para este conjunto de dados, a escolha entre KFold-10 e StratifiedShuffleSplit n√£o resultou em uma diferen√ßa expressiva na estimativa de acur√°cia .

No entanto, o **StratifiedShuffleSplit** oferece a vantagem de garantir a propor√ß√£o das classes (estratifica√ß√£o) em cada divis√£o de treino e teste. Esta √© uma pr√°tica recomendada para dados biom√©dicos, onde o desequil√≠brio entre classes √© comum .

Conclui-se que, embora ambos os m√©todos sejam eficazes, a escolha da estrat√©gia de valida√ß√£o deve ser consciente e justificada, com a **estratifica√ß√£o sendo um fator importante para a robustez da avalia√ß√£o do modelo** .

## üöÄ Como Executar o Projeto

Para executar a an√°lise localmente, siga os passos abaixo:

1.  **Clone o reposit√≥rio:**
    ```bash
    git clone <URL-do-repositorio>
    cd <nome-do-repositorio>
    ```

2.  **Instale as depend√™ncias:**
    √â recomendado criar um ambiente virtual.
    ```bash
    pip install pandas numpy matplotlib seaborn scikit-learn
    ```

3.  **Execute o Notebook:**
    Abra o arquivo `HD_Cleveland.ipynb` em um ambiente Jupyter (como Jupyter Notebook, JupyterLab ou Google Colab) e execute as c√©lulas sequencialmente. O dataset `Heart_disease_cleveland_new.csv` deve estar no mesmo diret√≥rio.

## üìÅ Estrutura dos Arquivos

* `HD_Cleveland.ipynb`: Notebook Jupyter contendo todo o c√≥digo da an√°lise, desde o carregamento dos dados at√© a visualiza√ß√£o dos resultados.
* `Heart_disease_cleveland_new.csv`: O conjunto de dados utilizado no estudo.
* `README.md`: Este arquivo.
